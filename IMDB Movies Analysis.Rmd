---
title: "PROJECT IMDB ANALYSIS"
author: "Yamileth Hercules"
date: "2022-11-12"
output:
  pdf_document: default
  word_document: default
---
# PREPARATION 
## Reading the table and seeing the first columns

```{r }
imdb_ds <-read.csv('imdb_top_1000.csv', header = TRUE,  na.string = c(""))
head(imdb_ds)
```
## Looking at the dimensions of the table
```{r}
dim(imdb_ds)
summary(imdb_ds)
```


## Looking at the data type
```{r}
str(imdb_ds)
```

## Subsetting the variables.

```{r}
subset_imdb <- imdb_ds[, -c(1,8,9,11,12,13,14)]
head(subset_imdb)
```
## Looking at the dimensions of the subset of data
```{r}

dim(subset_imdb)
```

## Looking at the variables with missing values 

```{r}
sum(is.na(subset_imdb))
summary(subset_imdb)
```

Observing the data carefully

There is an error in the the column Released Year in the dataset and it is going to be replaced with the value with more frequency

```{r}
unique(subset_imdb$Released_Year)
```


```{r}
subset_imdb$Released_Year[subset_imdb$Released_Year == 'PG'] <- '1995'
unique(subset_imdb$Released_Year)
View(subset_imdb)
```

# UNIVARIATE ANALYSIS
## Q1: How many movies are made per year (ranges) in the top 1000 IMDB? 

Making the year as numerical variable
```{r}
Realesed_year_variable <- strtoi(subset_imdb$Released_Year)
```


Generating the frequency table for the variable
```{r}
min<- min(subset_imdb$Released_Year)
max<- max(subset_imdb$Released_Year)
ry_table <-table(cut(Realesed_year_variable, breaks = seq(min, max, by =8)))

total<- sum(ry_table)

ryear_pct<-round((ry_table/total*100),2)

cbind(Frequency= ry_table, Percentage =ryear_pct)
```



```{r}
pal <- colorRampPalette(colors = c("lightblue", "blue", 'yellow'))(12)
```


```{r}
barplot(ry_table, ylab = "Frequency", xlab = 'Released Year in Ranges', main = "MOVIES PER YEAR", col= pal, legend.text = rownames(ry_table),xlim= c(0, 22))
#?barplot
```

_Conclusion:_
The barplot clearly shows that the proportion of movies are higher in the right side. There are more than 100 movies in the 3 latest ranges.The tendency is to increase the latest movies in the IMDB rating 

## Q2: What is the most prolific director in the top 1000 IMDB? 
(Categorical variable: Director)

```{r}
imdb_subset <-(subset_imdb$Director)
imdb_freq <- table(subset_imdb$Director)
head(imdb_freq)
```
```{r}
imdb_director <- table(imdb_subset)
imdb_director <-tail(sort(imdb_director),10)
imdb_director
```

```{r}
#install.packages("viridis")  # Install
library("viridis")           # Load
```
```{r}
barplot(imdb_director, ylab = "Frequency", xlab = '10 Most Prolific Director in IMDB', main = 'Director', col=viridis(10), legend.text = rownames(imdb_director), xlim = c(0,18))

```
_Conclusion:_
Alfred Hitchcock is the most prolific director in the IMDB movies.

## Q3: What is the proportion of movies per IMDB rating? 
(Numerical variable: IMDB rating) 

```{r}
imdb_rating <-(subset_imdb$IMDB_Rating)

```

```{r}
sd(imdb_rating)

```

```{r}
hist(imdb_rating, col = "lightblue", xlim = c(7.4,9.4))
```
The histogram is skewed to the right. There are a lot of movies that are rated under 8.

```{r}
boxplot(imdb_rating, horizontal=TRUE, col='steelblue',ylim =c(7.4,9.4))

```

```{r}
summary(imdb_rating)
```
The boxplot is showing that it is skewed to the right.The min is 7.6 and the max is 9.3. The mean is 7.949 and median is 7.9. There are 5 outliers.

# BIVARIATE ANALYSIS
## Q4: What is the correlation between votes and IMDB rating? 
(Numerical variables: Number_of_votes and IMDB rating)

1) Correlation analysis:

```{r}
plot(subset_imdb$No_of_Votes, subset_imdb$IMDB_Rating, xlab = 'Number of votes', ylab = 'IMDB Rating')
fit = lm(subset_imdb$IMDB_Rating ~ subset_imdb$No_of_Votes)
abline(fit, col = 'darkblue')
```

```{r}
cor(subset_imdb$No_of_Votes, subset_imdb$IMDB_Rating)
```

_Conclusion:_
There is a positive moderate correlation between the variables, there are some outliers.
 
---> Test for the significance correlation to verify if this correlation applies to the population or just to the sample:

__Hypothesis__
- Null hypothesis: The number of votes and the IMDB rating do not have linear correlation among all subjects in the population
- Alternative hypothesis: The number of votes and the IMDB rating have linear correlation among all subjects in the population

n = 1000
r = 0.4949
DP < 0.139

In this case r > DP, therefore, the x and y variable have positive linear relation among all subjects in the population so we have enough statistical evidence to reject the null hypothesis.

2) Regression analysis:

```{r}
summary(fit)
```

Formula: y = mx + b
           = 0.0000004165(x)+7.835

Intercept -> When one movie does not have audience votes, the intercept does not have meaning because the IMDB rating depends on the number of votes.
Slope -> When the number of votes varies by 1, the IMDB rating is going to increase 0.0000004165, in other words, one million votes are going to increase the IMDB rating by 0.41.

3) Validate the adequacy of the linear fit:

-->> Verify how reliable and valid is my linear analysis

a. Linearity and Homoscedasticity conditions:

```{r}
library(MASS)

residual <- resid(fit)
movies.residual <- studres(fit)
```

```{r}
plot(subset_imdb$No_of_Votes, movies.residual, xlab = 'No of votes', ylab = 'Residuals', main = 'Studentized residual plot')
abline(h = c(-2, 0, 2), col= c('blue', 'red', 'blue'), lty= c(2, 1, 2), lwd= c(3, 2, 3))
abline(h=0)
```


We consider that the linear and homoscedasticity conditions are valid because the values are distributed in the plot and they do not show any pattern.

b. Normal condition:


```{r}
pal2 <- colorRampPalette(colors = c("yellow", "blue", 'lightblue'))(14)
```

```{r}
hist(movies.residual, xlab = 'Residuals', main = 'Histogram of Studentized Residual', col = pal2)
```

The normal condition is valid because the residuals follow a Normal Distribution despite being slightly skewed to the right.

_Final conclusion:_ 
The analysis allows us to see that in the top 1000 movies the IMDB rating increases when the number of votes increases.


## Q5: What is the relation between movie duration (range under 90mn, 90mn-120mn, 120mn >) and decades? 
(Categorical variables: Runtime and Released_Year)

1) Converted the duration in a number by eliminating the string " min"
```{r}
# extract the minutes from Runtime column
duration_minute <- sapply(strsplit(subset_imdb$Runtime, split=' ', fixed=TRUE), function(x) (x[1]))
head(duration_minute)
```

2) Created ranges of duration, using the function getRange
```{r}
getRange0 <- function(dur) {
  ret <- ifelse (strtoi(dur)<90, "1. short <90mn",  ifelse( strtoi(dur)<120, "2. medium <2h", ifelse ( strtoi(dur)<180, "3. long <3h", "4. extra long >3h"))) 
  return(ret)
}

range_dur0 <- sapply(duration_minute, getRange0)
head(range_dur0)
```

```{r}
getRange <- function(dur) {
  ret <- ifelse(strtoi(dur)<91, "1. short <90mn",  ifelse( strtoi(dur)<121, "2. medium <2h", ifelse( strtoi(dur)<400, "3. long >2h" , "4."))) 
  return(ret)
}  

range_dur <- sapply(duration_minute, getRange)
head(range_dur)
```

3) Transformed the Released_Year in decades, using the function getDecade
```{r}
getDecade <- function(year) year - year%%10
  

released_decade0 = sapply(strtoi(subset_imdb$Released_Year), getDecade)
head(released_decade0)
```

```{r}
get2Decade <- function(year) {
  ret <- ifelse(year<1951, "1920-1950", ifelse( year<1971, "1960-1970" , ifelse( year<2000, "1980-1990", "2000+"))) 
  return(ret)
}

released_decade <-  sapply(strtoi(subset_imdb$Released_Year), get2Decade)
head(released_decade)
```

4) Created the 2 ways table for range of duration and released_decade
The first 2 ways table had many values under 5, so the chi-test was returning a warning saying the result might be incorrect. I modified both ranges of duration and group decades to get data that were above 5.
Used getDecade2 function to generate released_decade 
```{r}
decade_duration0 <- table(range_dur0, released_decade0)
decade_duration0
```
```{r}
decade_duration <- table(range_dur , released_decade)
decade_duration
```

5) Column wise conditional proportions
```{r}
cond_percent <- function(X) round(X/sum(X)*100,2) #in R can create a function anytime
apply(decade_duration0, 2,cond_percent ) #2 means column
```


```{r}
decade_duration_pct = apply(decade_duration, 2,cond_percent ) #2 means column
decade_duration_pct
```

6)	Draw a side-by-side bar graph for the two variables.
```{r}
barplot(decade_duration0, xlab="Decades", ylab="Frequency", legend.text=c("short", "medium", "long","very long"), args.legend= list(x="topleft", inset=c(0.05,0)), col=c("darkblue","blue","lightblue","lightgreen"), beside=TRUE, main="Movies duration over decades")
```

```{r}
barplot(decade_duration, xlab="Decades", ylab="Frequency", legend.text=c("short", "medium", "long"), args.legend= list(x="topleft", inset=c(0.05,0)), col=c("darkblue","blue","lightblue"), beside=TRUE, main="Movies duration over decades")
```

Interpretation: 
The groups of bars donâ€™t look alike, that can be interpreted as the 2 variables duration range and decades of release are not independent from each other. 

7) Run the Chi-square test
```{r}
chisq.test(decade_duration0) # Chi-square Test
```
Because of the warning, I created a two way table with less columns and rows.

```{r}
chisq.test(decade_duration) # Chi-square Test
```
__Hypothesis__
* H0: film duration and released year are independent to each other among all subjects in the population.
* H1: film duration and released year are not independent to each other among all subjects in the population.
Calculated the Chi-square statistic with R
	Pearson's Chi-squared test
data:  decade_duration
X-squared = 63.937, df = 6, p-value = 7.11e-12

_Interpretation and Conlusion_
Looking for the Decision Point in the Statistics table for the degree of freedom =6, Decision point = 12.59
X-squared (= 63.937) is greater than the Decision Point (DP =12.59), we can then reject the H0 hypothesis and conclude that the 2 variables are not independent.
The year or decade a film is released has an influence on the duration of the film. There is a trend to produce longer movies in the more recent decades. 



